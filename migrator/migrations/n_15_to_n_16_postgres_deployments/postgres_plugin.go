// Code generated by pg-bindings generator. DO NOT EDIT.

package n15ton16

import (
	"context"

	"github.com/jackc/pgx/v4"
	"github.com/stackrox/rox/generated/storage"
	ops "github.com/stackrox/rox/pkg/metrics"
	"github.com/stackrox/rox/pkg/postgres/pgutils"
)

func (s *storeImpl) copyFromDeployments(ctx context.Context, tx pgx.Tx, objs ...*storage.Deployment) error {

	inputRows := [][]interface{}{}

	var err error

	// This is a copy so first we must delete the rows and re-add them
	// Which is essentially the desired behaviour of an upsert.
	var deletes []string

	copyCols := []string{

		"id",

		"name",

		"type",

		"namespace",

		"namespaceid",

		"orchestratorcomponent",

		"labels",

		"podlabels",

		"created",

		"clusterid",

		"clustername",

		"annotations",

		"priority",

		"imagepullsecrets",

		"serviceaccount",

		"serviceaccountpermissionlevel",

		"riskscore",

		"processtags",

		"serialized",
	}

	for idx, obj := range objs {
		// Todo: ROX-9499 Figure out how to more cleanly template around this issue.
		log.Debugf("This is here for now because there is an issue with pods_TerminatedInstances where the obj in the loop is not used as it only consists of the parent id and the idx.  Putting this here as a stop gap to simply use the object.  %s", obj)

		serialized, marshalErr := obj.Marshal()
		if marshalErr != nil {
			return marshalErr
		}

		inputRows = append(inputRows, []interface{}{

			obj.GetId(),

			obj.GetName(),

			obj.GetType(),

			obj.GetNamespace(),

			obj.GetNamespaceId(),

			obj.GetOrchestratorComponent(),

			obj.GetLabels(),

			obj.GetPodLabels(),

			pgutils.NilOrTime(obj.GetCreated()),

			obj.GetClusterId(),

			obj.GetClusterName(),

			obj.GetAnnotations(),

			obj.GetPriority(),

			obj.GetImagePullSecrets(),

			obj.GetServiceAccount(),

			obj.GetServiceAccountPermissionLevel(),

			obj.GetRiskScore(),

			obj.GetProcessTags(),

			serialized,
		})

		// Add the id to be deleted.
		deletes = append(deletes, obj.GetId())

		// if we hit our batch size we need to push the data
		if (idx+1)%batchSize == 0 || idx == len(objs)-1 {
			// copy does not upsert so have to delete first.  parent deletion cascades so only need to
			// delete for the top level parent

			if err := s.DeleteMany(ctx, deletes); err != nil {
				return err
			}
			// clear the inserts and vals for the next batch
			deletes = nil

			_, err = tx.CopyFrom(ctx, pgx.Identifier{"deployments"}, copyCols, pgx.CopyFromRows(inputRows))

			if err != nil {
				return err
			}

			// clear the input rows for the next batch
			inputRows = inputRows[:0]
		}
	}

	for idx, obj := range objs {
		_ = idx // idx may or may not be used depending on how nested we are, so avoid compile-time errors.

		if err = s.copyFromDeploymentsContainers(ctx, tx, obj.GetId(), obj.GetContainers()...); err != nil {
			return err
		}
		if err = s.copyFromDeploymentsPorts(ctx, tx, obj.GetId(), obj.GetPorts()...); err != nil {
			return err
		}
	}

	return err
}

func (s *storeImpl) copyFromDeploymentsContainers(ctx context.Context, tx pgx.Tx, deployments_Id string, objs ...*storage.Container) error {

	inputRows := [][]interface{}{}

	var err error

	copyCols := []string{

		"deployments_id",

		"idx",

		"image_id",

		"image_name_registry",

		"image_name_remote",

		"image_name_tag",

		"image_name_fullname",

		"securitycontext_privileged",

		"securitycontext_dropcapabilities",

		"securitycontext_addcapabilities",

		"securitycontext_readonlyrootfilesystem",

		"resources_cpucoresrequest",

		"resources_cpucoreslimit",

		"resources_memorymbrequest",

		"resources_memorymblimit",
	}

	for idx, obj := range objs {
		// Todo: ROX-9499 Figure out how to more cleanly template around this issue.
		log.Debugf("This is here for now because there is an issue with pods_TerminatedInstances where the obj in the loop is not used as it only consists of the parent id and the idx.  Putting this here as a stop gap to simply use the object.  %s", obj)

		inputRows = append(inputRows, []interface{}{

			deployments_Id,

			idx,

			obj.GetImage().GetId(),

			obj.GetImage().GetName().GetRegistry(),

			obj.GetImage().GetName().GetRemote(),

			obj.GetImage().GetName().GetTag(),

			obj.GetImage().GetName().GetFullName(),

			obj.GetSecurityContext().GetPrivileged(),

			obj.GetSecurityContext().GetDropCapabilities(),

			obj.GetSecurityContext().GetAddCapabilities(),

			obj.GetSecurityContext().GetReadOnlyRootFilesystem(),

			obj.GetResources().GetCpuCoresRequest(),

			obj.GetResources().GetCpuCoresLimit(),

			obj.GetResources().GetMemoryMbRequest(),

			obj.GetResources().GetMemoryMbLimit(),
		})

		// if we hit our batch size we need to push the data
		if (idx+1)%batchSize == 0 || idx == len(objs)-1 {
			// copy does not upsert so have to delete first.  parent deletion cascades so only need to
			// delete for the top level parent

			_, err = tx.CopyFrom(ctx, pgx.Identifier{"deployments_containers"}, copyCols, pgx.CopyFromRows(inputRows))

			if err != nil {
				return err
			}

			// clear the input rows for the next batch
			inputRows = inputRows[:0]
		}
	}

	for idx, obj := range objs {
		_ = idx // idx may or may not be used depending on how nested we are, so avoid compile-time errors.

		if err = s.copyFromDeploymentsContainersEnvs(ctx, tx, deployments_Id, idx, obj.GetConfig().GetEnv()...); err != nil {
			return err
		}
		if err = s.copyFromDeploymentsContainersVolumes(ctx, tx, deployments_Id, idx, obj.GetVolumes()...); err != nil {
			return err
		}
		if err = s.copyFromDeploymentsContainersSecrets(ctx, tx, deployments_Id, idx, obj.GetSecrets()...); err != nil {
			return err
		}
	}

	return err
}

func (s *storeImpl) copyFromDeploymentsContainersEnvs(ctx context.Context, tx pgx.Tx, deployments_Id string, deployments_containers_idx int, objs ...*storage.ContainerConfig_EnvironmentConfig) error {

	inputRows := [][]interface{}{}

	var err error

	copyCols := []string{

		"deployments_id",

		"deployments_containers_idx",

		"idx",

		"key",

		"value",

		"envvarsource",
	}

	for idx, obj := range objs {
		// Todo: ROX-9499 Figure out how to more cleanly template around this issue.
		log.Debugf("This is here for now because there is an issue with pods_TerminatedInstances where the obj in the loop is not used as it only consists of the parent id and the idx.  Putting this here as a stop gap to simply use the object.  %s", obj)

		inputRows = append(inputRows, []interface{}{

			deployments_Id,

			deployments_containers_idx,

			idx,

			obj.GetKey(),

			obj.GetValue(),

			obj.GetEnvVarSource(),
		})

		// if we hit our batch size we need to push the data
		if (idx+1)%batchSize == 0 || idx == len(objs)-1 {
			// copy does not upsert so have to delete first.  parent deletion cascades so only need to
			// delete for the top level parent

			_, err = tx.CopyFrom(ctx, pgx.Identifier{"deployments_containers_envs"}, copyCols, pgx.CopyFromRows(inputRows))

			if err != nil {
				return err
			}

			// clear the input rows for the next batch
			inputRows = inputRows[:0]
		}
	}

	return err
}

func (s *storeImpl) copyFromDeploymentsContainersVolumes(ctx context.Context, tx pgx.Tx, deployments_Id string, deployments_containers_idx int, objs ...*storage.Volume) error {

	inputRows := [][]interface{}{}

	var err error

	copyCols := []string{

		"deployments_id",

		"deployments_containers_idx",

		"idx",

		"name",

		"source",

		"destination",

		"readonly",

		"type",
	}

	for idx, obj := range objs {
		// Todo: ROX-9499 Figure out how to more cleanly template around this issue.
		log.Debugf("This is here for now because there is an issue with pods_TerminatedInstances where the obj in the loop is not used as it only consists of the parent id and the idx.  Putting this here as a stop gap to simply use the object.  %s", obj)

		inputRows = append(inputRows, []interface{}{

			deployments_Id,

			deployments_containers_idx,

			idx,

			obj.GetName(),

			obj.GetSource(),

			obj.GetDestination(),

			obj.GetReadOnly(),

			obj.GetType(),
		})

		// if we hit our batch size we need to push the data
		if (idx+1)%batchSize == 0 || idx == len(objs)-1 {
			// copy does not upsert so have to delete first.  parent deletion cascades so only need to
			// delete for the top level parent

			_, err = tx.CopyFrom(ctx, pgx.Identifier{"deployments_containers_volumes"}, copyCols, pgx.CopyFromRows(inputRows))

			if err != nil {
				return err
			}

			// clear the input rows for the next batch
			inputRows = inputRows[:0]
		}
	}

	return err
}

func (s *storeImpl) copyFromDeploymentsContainersSecrets(ctx context.Context, tx pgx.Tx, deployments_Id string, deployments_containers_idx int, objs ...*storage.EmbeddedSecret) error {

	inputRows := [][]interface{}{}

	var err error

	copyCols := []string{

		"deployments_id",

		"deployments_containers_idx",

		"idx",

		"name",

		"path",
	}

	for idx, obj := range objs {
		// Todo: ROX-9499 Figure out how to more cleanly template around this issue.
		log.Debugf("This is here for now because there is an issue with pods_TerminatedInstances where the obj in the loop is not used as it only consists of the parent id and the idx.  Putting this here as a stop gap to simply use the object.  %s", obj)

		inputRows = append(inputRows, []interface{}{

			deployments_Id,

			deployments_containers_idx,

			idx,

			obj.GetName(),

			obj.GetPath(),
		})

		// if we hit our batch size we need to push the data
		if (idx+1)%batchSize == 0 || idx == len(objs)-1 {
			// copy does not upsert so have to delete first.  parent deletion cascades so only need to
			// delete for the top level parent

			_, err = tx.CopyFrom(ctx, pgx.Identifier{"deployments_containers_secrets"}, copyCols, pgx.CopyFromRows(inputRows))

			if err != nil {
				return err
			}

			// clear the input rows for the next batch
			inputRows = inputRows[:0]
		}
	}

	return err
}

func (s *storeImpl) copyFromDeploymentsPorts(ctx context.Context, tx pgx.Tx, deployments_Id string, objs ...*storage.PortConfig) error {

	inputRows := [][]interface{}{}

	var err error

	copyCols := []string{

		"deployments_id",

		"idx",

		"containerport",

		"protocol",

		"exposure",
	}

	for idx, obj := range objs {
		// Todo: ROX-9499 Figure out how to more cleanly template around this issue.
		log.Debugf("This is here for now because there is an issue with pods_TerminatedInstances where the obj in the loop is not used as it only consists of the parent id and the idx.  Putting this here as a stop gap to simply use the object.  %s", obj)

		inputRows = append(inputRows, []interface{}{

			deployments_Id,

			idx,

			obj.GetContainerPort(),

			obj.GetProtocol(),

			obj.GetExposure(),
		})

		// if we hit our batch size we need to push the data
		if (idx+1)%batchSize == 0 || idx == len(objs)-1 {
			// copy does not upsert so have to delete first.  parent deletion cascades so only need to
			// delete for the top level parent

			_, err = tx.CopyFrom(ctx, pgx.Identifier{"deployments_ports"}, copyCols, pgx.CopyFromRows(inputRows))

			if err != nil {
				return err
			}

			// clear the input rows for the next batch
			inputRows = inputRows[:0]
		}
	}

	for idx, obj := range objs {
		_ = idx // idx may or may not be used depending on how nested we are, so avoid compile-time errors.

		if err = s.copyFromDeploymentsPortsExposureInfos(ctx, tx, deployments_Id, idx, obj.GetExposureInfos()...); err != nil {
			return err
		}
	}

	return err
}

func (s *storeImpl) copyFromDeploymentsPortsExposureInfos(ctx context.Context, tx pgx.Tx, deployments_Id string, deployments_ports_idx int, objs ...*storage.PortConfig_ExposureInfo) error {

	inputRows := [][]interface{}{}

	var err error

	copyCols := []string{

		"deployments_id",

		"deployments_ports_idx",

		"idx",

		"level",

		"servicename",

		"serviceport",

		"nodeport",

		"externalips",

		"externalhostnames",
	}

	for idx, obj := range objs {
		// Todo: ROX-9499 Figure out how to more cleanly template around this issue.
		log.Debugf("This is here for now because there is an issue with pods_TerminatedInstances where the obj in the loop is not used as it only consists of the parent id and the idx.  Putting this here as a stop gap to simply use the object.  %s", obj)

		inputRows = append(inputRows, []interface{}{

			deployments_Id,

			deployments_ports_idx,

			idx,

			obj.GetLevel(),

			obj.GetServiceName(),

			obj.GetServicePort(),

			obj.GetNodePort(),

			obj.GetExternalIps(),

			obj.GetExternalHostnames(),
		})

		// if we hit our batch size we need to push the data
		if (idx+1)%batchSize == 0 || idx == len(objs)-1 {
			// copy does not upsert so have to delete first.  parent deletion cascades so only need to
			// delete for the top level parent

			_, err = tx.CopyFrom(ctx, pgx.Identifier{"deployments_ports_exposure_infos"}, copyCols, pgx.CopyFromRows(inputRows))

			if err != nil {
				return err
			}

			// clear the input rows for the next batch
			inputRows = inputRows[:0]
		}
	}

	return err
}

func (s *storeImpl) copyFrom(ctx context.Context, objs ...*storage.Deployment) error {
	conn, release, err := s.acquireConn(ctx, ops.Get, "Deployment")
	if err != nil {
		return err
	}
	defer release()

	tx, err := conn.Begin(ctx)
	if err != nil {
		return err
	}

	if err := s.copyFromDeployments(ctx, tx, objs...); err != nil {
		if err := tx.Rollback(ctx); err != nil {
			return err
		}
		return err
	}
	if err := tx.Commit(ctx); err != nil {
		return err
	}
	return nil
}
